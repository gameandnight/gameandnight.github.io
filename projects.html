<!DOCTYPE html>
<html lang="es">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Proyectos - Iker Redondo Serra</title>
    <meta name="description" content="Proyectos de ML e IA generativa de Iker Redondo Serra.">
    <!-- Canonical -->
    <link rel="canonical" href="https://gameandnight.github.io/projects.html">
    <!-- Open Graph -->
    <meta property="og:title" content="Proyectos – Iker Redondo Serra">
    <meta property="og:description" content="Descubre los proyectos de ML e IA generativa de Iker Redondo Serra.">
    <meta property="og:url" content="https://gameandnight.github.io/projects.html">
    <meta property="og:image" content="https://gameandnight.github.io/assets/images/proyecto-ejemplo.jpg">
    <meta property="og:type" content="website">
    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Proyectos – Iker Redondo Serra">
    <meta name="twitter:description" content="Descubre los proyectos de ML e IA generativa de Iker Redondo Serra.">
    <meta name="twitter:image" content="https://gameandnight.github.io/assets/images/proyecto-ejemplo.jpg">
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
      .nav-link[aria-current="page"] {
        font-weight: bold;
        color: #0d6efd;
      }
    </style>
  </head>
  <body>
    <nav class="navbar navbar-expand-lg navbar-light bg-light">
      <div class="container-fluid">
        <a class="navbar-brand" href="/">Iker Redondo Serra</a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav"
                aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarNav">
          <ul class="navbar-nav ms-auto">
            <li class="nav-item">
              <a class="nav-link" href="/">Inicio</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="/about.html">Sobre mí</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="/projects.html" aria-current="page">Proyectos</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="/contact.html">Contacto</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="/assets/cv/CV.pdf" target="_blank" rel="noopener">Descargar CV</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <section class="bg-light py-5">
      <div class="container">
        <h1>Proyectos Destacados</h1>
        <!-- Ejemplo de proyecto: Fine-tuning GPT-2 -->
        <div class="row mb-4">
          <div class="col-md-4">
            <img src="/assets/images/proyecto-ejemplo.jpg" alt="Proyecto Ejemplo" class="img-fluid rounded">
          </div>
          <div class="col-md-8">
            <h3>Fine-tuning GPT-2 para resúmenes</h3>
            <p>Pipeline de preprocesamiento, entrenamiento en Colab, evaluación y despliegue de demo en Streamlit.</p>
            <p>
              <a href="https://github.com/gameandnight/proyecto-gpt2-resumen" class="btn btn-primary btn-sm" target="_blank" rel="noopener">Código</a>
              <a href="https://tu-app.streamlitapp.com" class="btn btn-secondary btn-sm" target="_blank" rel="noopener">Demo</a>
              <a href="https://www.youtube.com/watch?v=ID_DEL_VIDEO" class="btn btn-info btn-sm" target="_blank" rel="noopener">Ver Vídeo</a>
            </p>
          </div>
        </div>
        <!-- Más proyectos: duplica este bloque cambiando título, descripción, imagen y enlaces -->
      </div>
    </section>

    <section class="bg-light py-5">
      <div class="container">
        <h1>Proyectos Destacados</h1>

        <!-- Proyecto: Detección de señales de tráfico con YOLO11x -->
        <div class="row mb-4">
          <div class="col-md-4">
            <img src="/assets/images/deteccion-senales.jpg" alt="Detección de señales de tráfico con YOLO11x" class="img-fluid rounded">
          </div>
          <div class="col-md-8">
            <h3>Detección de señales de tráfico con YOLO11x</h3>
            <p>Fine-tuning de YOLO11x para detección de señales de tráfico en tiempo real usando la webcam.</p>
            <p><strong>Pipeline:</strong>
            </p>
            <ul>
              <li>Etiquetado con CVAT y exportación al formato YOLO.</li>
              <li>Entrenamiento en GPU: variantes YOLO11n → YOLO11x, ajuste de hiperparámetros.</li>
              <li>Pruebas en tiempo real: webcam, detección y síntesis de voz de la señal detectada.</li>
              <li>Optimización de clases y balanceo para reducir falsos positivos.</li>
            </ul>
            <p>
              <a href="https://github.com/gameandnight/deteccion-senales" class="btn btn-primary btn-sm" target="_blank" rel="noopener">Código</a>
              <!-- <a href="https://tu-demo.streamlitapp.com" class="btn btn-secondary btn-sm" target="_blank" rel="noopener">Demo</a> -->
              <a href="https://www.youtube.com/watch?v=ID_VIDEO_DETECCION" class="btn btn-info btn-sm" target="_blank" rel="noopener">Ver Vídeo</a>
            </p>
            <!-- Opcional embed:
            <div class="mt-3">
              <div class="ratio ratio-16x9">
                <iframe src="https://www.youtube.com/embed/ID_VIDEO_DETECCION" title="Demo detección señales" allowfullscreen></iframe>
              </div>
            </div>
            -->
          </div>
        </div>

        <!-- Proyecto: Suite de Mini Juegos controlados con gestos (OpenCV + Tkinter) -->
        <div class="row mb-4">
          <div class="col-md-4">
            <img src="/assets/images/mini-juegos-gestos.jpg" alt="Suite de Mini Juegos controlados con gestos" class="img-fluid rounded">
          </div>
          <div class="col-md-8">
            <h3>Suite de Mini Juegos controlados con gestos (OpenCV + Tkinter)</h3>
            <p>Aplicación en Python que ofrece varios mini juegos interactivos controlados mediante gestos o pose corporal, usando OpenCV y una interfaz Tkinter.</p>
            <p><strong>Descripción general / Pipeline:</strong>
            </p>
            <ul>
              <li>Launcher en Tkinter con botones para cada mini juego: "Manos", “Cuerpo”, “Dibujar”, “Atrapa la pelota”, “Piedra, Papel o Tijera” y “Snake”.</li>
              <li>Para detección de landmarks de mano y pose se emplea CVZone PoseModule/HandTracking, facilitando el uso de MediaPipe para extraer coordenadas clave.</li>
              <li>Lógica de cada mini juego: captura de cámara con <code>cv2.VideoCapture</code>, procesamiento de frames, interpretación de gestos para mover sprites, dibujar o decidir jugadas.</li>
              <li>Manejo de eventos de teclado (‘q’ para salir) y retorno al menú sin cerrar la app por completo.</li>
              <li>Pruebas y calibraciones para asegurar suficiente FPS y detección estable en distintas condiciones de iluminación.</li>
            </ul>
            <p>
              <a href="https://github.com/gameandnight/mini-juegos-gestos" class="btn btn-primary btn-sm" target="_blank" rel="noopener">Código</a>
              <!-- <a href="https://tu-demo-mini-juegos.streamlitapp.com" class="btn btn-secondary btn-sm" target="_blank" rel="noopener">Demo</a> -->
              <a href="https://www.youtube.com/watch?v=ID_VIDEO_MINIJUEGOS" class="btn btn-info btn-sm" target="_blank" rel="noopener">Ver Vídeo</a>
            </p>
            <!-- Opcional embed:
            <div class="mt-3">
              <div class="ratio ratio-16x9">
                <iframe src="https://www.youtube.com/embed/ID_VIDEO_MINIJUEGOS" title="Demo Mini Juegos controlados con gestos" allowfullscreen></iframe>
              </div>
            </div>
            -->
          </div>
        </div>

        <!-- Más proyectos: duplica bloques anteriores y ajusta -->
      </div>

      <!-- Proyecto: Juego de Trivial controlado con gestos (OpenCV + CVZone + Tkinter) -->
      <div class="row mb-4">
        <div class="col-md-4">
          <!-- Imagen representativa: sube captura en assets/images/trivial-gestos.jpg -->
          <img src="/assets/images/trivial-gestos.jpg" alt="Juego de Trivial controlado con gestos" class="img-fluid rounded">
        </div>
        <div class="col-md-8">
          <h3>Juego de Trivial controlado con gestos (OpenCV + CVZone + Tkinter)</h3>
          <p>Aplicación en Python que presenta preguntas de trivia en diferentes categorías, permitiendo seleccionar la respuesta mediante gestos de mano (rock/paper/scissors) capturados por la webcam.</p>
          <p><strong>Descripción general / Pipeline:</strong></p>
          <ul>
            <li><strong>Interfaz de menú con Tkinter:</strong> Al iniciar, se muestra una ventana Tkinter con botones para cada categoría de preguntas (p. ej. ESO, Bachiller, Informática). El usuario selecciona una categoría para iniciar el trivial.</li>
            <li><strong>Carga de preguntas:</strong> El código lee archivos JSON con preguntas y opciones (por ejemplo <code>questions_eso.json</code>, <code>questions_bachiller.json</code>), donde cada elemento incluye la pregunta, las opciones y el índice de la respuesta correcta.</li>
            <li><strong>Preparación de recursos visuales:</strong> Se carga una imagen de fondo (<code>Resources/BG.png</code>) redimensionada a la resolución de la ventana (p.ej. 1280×720). Se preparan imágenes de feedback (correcto/incorrecto) (<code>correct.wav</code>, <code>incorrect.wav</code>) y sprites opcionales.</li>
            <li><strong>Captura de cámara y detección de gestos:</strong>
              <ul>
                <li>Se inicializa <code>cv2.VideoCapture(0)</code> para capturar frames de la webcam.</li>
                <li>Se utiliza CVZone HandDetector (basado en MediaPipe) para detectar la mano y extraer landmarks, con los cuales se interpreta el gesto rock/paper/scissors como selección de respuesta. Esto permite mapear cada opción a un gesto: “Piedra”, “Papel” o “Tijeras”. :contentReference[oaicite:0]{index=0}</li>
                <li>En cada pregunta, tras mostrarla en pantalla, se espera a que el detector identifique claramente uno de los gestos. Durante esta espera, se muestra la imagen de fondo más un recuadro con el feed de cámara, indicando al usuario que haga el gesto.</li>
              </ul>
            </li>
            <li><strong>Síntesis de voz y feedback:</strong>
              <ul>
                <li>Se usa gTTS para convertir a audio el texto de la pregunta y de las opciones, generando un archivo de audio temporal que se reproduce (por ejemplo con pygame) para narrar la pregunta y las opciones. :contentReference[oaicite:1]{index=1}</li>
                <li>Tras que el usuario hace el gesto y se detecta la elección, se compara con la respuesta correcta almacenada en JSON.</li>
                <li>Se reproduce un sonido o mensaje de audio indicando “Correcto” o “Incorrecto” (<code>Resources/correct.wav</code> / <code>Resources/incorrect.wav</code>).</li>
              </ul>
            </li>
            <li><strong>Lógica de flujo de juego:</strong>
              <ul>
                <li>Se muestra la pregunta y se invoca la narración por voz.</li>
                <li>Se espera la selección por gesto; si no se detecta tras cierto tiempo, se puede repetir la pregunta o avisar al usuario.</li>
                <li>Tras respuesta, se muestra feedback y pasa a la siguiente pregunta o finaliza la ronda.</li>
                <li>Al finalizar la categoría o al pulsar la tecla ‘q’, se cierra la ventana de OpenCV y se regresa al menú Tkinter.</li>
              </ul>
            </li>
            <li><strong>Configuración y calibración:</strong>
              <ul>
                <li>Permite ajustar la confianza del detector de manos y la sensibilidad de reconocimiento de gestos para funcionar en distintas condiciones de iluminación.</li>
                <li>Verifica FPS para asegurar experiencia fluida. Si la velocidad de detección es baja, se puede reducir la resolución o ajustar parámetros del detector.</li>
              </ul>
            </li>
            <li><strong>Gestión de archivos:</strong>
              <ul>
                <li>Archivos JSON en carpeta raíz o en <code>Resources/</code>, por ejemplo <code>questions_eso.json</code>, <code>questions_bachiller.json</code>, <code>questions_profesores.json</code>.</li>
                <li>Recursos en <code>Resources/</code>: <code>BG.png</code>, <code>correct.wav</code>, <code>incorrect.wav</code>, y otros assets.</li>
              </ul>
            </li>
            <li><strong>Dependencias:</strong>
              <ul>
                <li>Python 3.x</li>
                <li>OpenCV (<code>opencv-python</code>)</li>
                <li>CVZone (<code>cvzone</code>, requiere <code>mediapipe</code>)</li>
                <li>gTTS (<code>gtts</code>), pygame (para reproducir audio) o librería similar</li>
                <li>Pillow (<code>PIL</code>) para dibujar texto sobre la imagen con fuentes personalizadas</li>
                <li>Tkinter (incluido en la mayoría de distribuciones Python) para la GUI del menú</li>
                <li>Otros: <code>numpy</code>, <code>random</code>, <code>time</code>, <code>json</code> etc.</li>
              </ul>
            </li>
            <li><strong>Pruebas y grabación de demo:</strong>
              <ul>
                <li>Grabar con OBS o Game Bar mostrando la ventana Tkinter de selección y luego la sesión de trivial: pregunta en pantalla, usuario realiza gesto, detección y feedback de voz.</li>
                <li>Tomar capturas de pantalla para la imagen representativa del proyecto en tu portfolio.</li>
              </ul>
            </li>
          </ul>
          <p>
            <!-- Enlace al repositorio de código: reemplaza con tu URL real -->
            <a href="https://github.com/gameandnight/trivia-gestos" class="btn btn-primary btn-sm" target="_blank" rel="noopener">Código</a>
            <!-- Si tuvieras demo online, descomenta y ajusta este enlace -->
            <!-- <a href="https://tu-demo-trivia.streamlitapp.com" class="btn btn-secondary btn-sm" target="_blank" rel="noopener">Demo</a> -->
            <!-- Enlace a vídeo de demostración en YouTube mostrando el flujo completo del trivial controlado con gestos -->
            <a href="https://www.youtube.com/watch?v=ID_VIDEO_TRIVIAL" class="btn btn-info btn-sm" target="_blank" rel="noopener">Ver Vídeo</a>
          </p>
          <!-- Embed de vídeo (opcional): descomentar si deseas embeber el vídeo directamente -->
          <!--
          <div class="mt-3">
            <div class="ratio ratio-16x9">
              <iframe src="https://www.youtube.com/embed/ID_VIDEO_TRIVIAL" title="Demo Juego de Trivial con gestos" allowfullscreen></iframe>
            </div>
          </div>
          -->
        </div>

        <!-- Proyecto: Juego de Plataformas y Shooter de Naves controlado con gestos RPS -->
        <div class="row mb-4">
          <div class="col-md-4">
            <!-- Imagen representativa: sube capturas de cada nivel en assets/images/ -->
            <img src="/assets/images/juego-plataformas-naves-gestos.jpg" alt="Juego Plataformas y Naves controlado con gestos" class="img-fluid rounded">
          </div>
          <div class="col-md-8">
            <h3>Juego de Plataformas y Shooter de Naves controlado con gestos RPS</h3>
            <p>Aplicación en Python que combina dos niveles de plataformas y un tercer nivel de shooter de naves con scroll automático y boss final, controlados mediante gestos de mano (Rock/Paper/Scissors) detectados con la webcam.</p>
            <p><strong>Descripción general / Pipeline:</strong></p>
            <ul>
              <li><strong>Estructura modular:</strong>
                <ul>
                  <li><code>game.py</code>: Punto de entrada. Inicializa Pygame, HandDetector (CVZone) y controla el bucle principal, alternando entre modos de plataforma y modo shooter según selección.</li>
                  <li><code>gestures.py</code>: Función <code>detect_gesture</code> que recibe lista de manos detectadas por <code>HandDetector</code> y devuelve “piedra”, “papel” o “tijeras” según dedos levantados (rock/paper/scissors). Mapea cada gesto a acciones del juego.</li>
                  <li><code>modePlatform.py</code>: Lógica de niveles de plataformas. Obtiene datos de cada nivel desde <code>levels.py</code>, usa <code>pantalla.py</code> para dibujar fondos, bloques, obstáculos, nubes, árboles y UI, y <code>player.py</code> para la clase Player con física (gravedad, salto, colisiones).</li>
                  <li><code>modeSpace.py</code>: Lógica del shooter de naves. Usa <code>spaceship.py</code> para la clase de la nave del jugador, <code>pantalla.py</code> para dibujar fondo espacial, obstáculos y UI, y controla enemigos, disparos y boss final.</li>
                  <li><code>pantalla.py</code>: Funciones para dibujar la interfaz común: parallax backgrounds, UI (vidas, puntuación), obstáculos, sprites, textos en pantalla, gestionando carga única de assets para optimizar rendimiento.</li>
                  <li><code>player.py</code> y <code>spaceship.py</code>: Definen las clases de entidad del jugador: atributos como posición, velocidad, animaciones o sprites, métodos de actualización de posición, colisiones y dibujo en pantalla.</li>
                  <li><code>levels.py</code>: Definición de cada nivel de plataforma (coordenadas de bloques, obstáculos, nubes, trees, enemigos) y funciones para colisiones y generación de contenido procedimental o estático según nivel. También patrones para shooter (enemigos, spawn, boss).</li>
                  <li><code>sound.py</code>: Inicialización y reproducción de música de fondo y efectos de sonido (salto, disparo, explosiones, boss defeat), usando <code>pygame.mixer</code> u otra librería de audio.</li>
                  <li><code>assets/</code>: Carpeta con imágenes (fondos: <code>background1.png</code>, <code>background2.png</code>..., imágenes de naves, enemigos, sprites de gesto: <code>Rock.png</code>, <code>Paper.png</code>, <code>Scissors.png</code> para mostrar al usuario zona de detección), sonidos (<code>jump.wav</code>, <code>shoot.wav</code>, <code>explosion.wav</code>, etc.), configuraciones JSON o CSV para parámetros de niveles o patrones de enemigo.</li>
                </ul>
              </li>
              <li><strong>Interfaz de inicio / menú:</strong>
                <ul>
                  <li>Ventana inicial (Tkinter o Pygame): muestra opciones “Nivel 1 (Plataformas)”, “Nivel 2 (Plataformas avanzado)”, “Nivel 3 (Shooter de naves)”.</li>
                  <li>Al elegir nivel, se inicia el modo correspondiente en <code>game.py</code>, que llama a <code>modePlatform.modePlatform(...)</code> o <code>modeSpace.modeSpace(...)</code> con parámetros de configuración (resolución, velocidad, assets cargados, detector de gestos).</li>
                </ul>
              </li>
              <li><strong>Captura de cámara y detección de gestos:</strong>
                <ul>
                  <li>Se inicializa <code>cv2.VideoCapture(0)</code> para leer frames de la webcam.</li>
                  <li>Se crea <code>HandDetector(detectionCon=0.8, maxHands=1)</code> de CVZone para detectar mano y extraer landmarks de MediaPipe con pocas líneas de código.</li>
                  <li>En cada frame, <code>hands, frame = detector.findHands(frame)</code> devuelve lista de manos detectadas y dibuja recuadros sobre la imagen. Luego <code>detect_gesture(hands, detector)</code> evalúa <code>detector.fingersUp(hand)</code> y devuelve:
                    <ul>
                      <li><strong>“piedra”</strong>: en niveles de plataforma se interpreta como “avanzar” o “moverse adelante”; en shooter, podría mapearse a “subir” o acción de movimiento vertical.</li>
                      <li><strong>“papel”</strong>: en plataformas se mapea a “saltar” (salto normal o más alto en nivel 2); en shooter, mapea a “disparar” o activar arma principal.</li>
                      <li><strong>“tijeras”</strong>: en plataformas se mapea a “retroceder” o “acción secundaria” (por ejemplo, deslizarse o agacharse); en shooter, mapea a “bajar” o “cambiar arma/escudo”.</li>
                    </ul>
                  </li>
                  <li>En pantalla de juego, se puede mostrar un recuadro pequeño con feed de cámara y/o íconos de <code>Rock.png</code>, <code>Paper.png</code>, <code>Scissors.png</code> para guiar al usuario y confirmar gesto detectado, ayudando a calibrar posición de la mano.</li>
                </ul>
              </li>
              <li><strong>Niveles de Plataformas (Level 1 y Level 2):</strong>
                <ul>
                  <li>Datos de nivel cargados desde <code>levels.py</code>: arrays de bloques, obstáculos, nubes, árboles y enemigos. Level 2 añade complejidad: plataformas móviles, enemigos básicos con patrones de movimiento.</li>
                  <li>Clase <code>Player</code> en <code>player.py</code> gestiona posición, velocidad vertical (gravedad), colisiones con bloques y enemigos. Según gesto:
                    <ul>
                      <li>“piedra”: mueve al jugador hacia la derecha con velocidad definida.</li>
                      <li>“papel”: activa salto (ajustando <code>player.velocity_y</code>), con animación de salto y sonido (<code>jump.wav</code>).</li>
                      <li>“tijeras”: acción secundaria (p.ej. agacharse, deslizarse o disparo de proyectil en plataformas, según diseño), con animación y sonido opcional.</li>
                    </ul>
                  </li>
                  <li>En cada iteración del bucle de <code>modePlatform</code>:
                    <ul>
                      <li>Se actualiza posición del jugador y posición de scroll (scroll_x) para simular avance por el nivel.</li>
                      <li><code>pantalla.draw_parallax_background</code> dibuja fondo con efecto parallax según scroll_x.</li>
                      <li><code>pantalla.draw_obstacles</code>, <code>draw_blocks</code>, <code>draw_powerups</code> dibujan elementos del nivel.</li>
                      <li>Se detectan colisiones mediante funciones en <code>levels.py</code> (por ejemplo, colisión jugador-plataforma, jugador-enemigo). Si colisión con enemigo: restar vida o reiniciar punto de control.</li>
                      <li>Se reproduce música de fondo y efectos mediante <code>sound.play_music</code> y <code>play_sound</code> (salto, impacto, recogida de power-up).</li>
                      <li>Al completar todos los bloques o alcanzar meta: marcar nivel completado y mostrar mensaje “Nivel completado” en pantalla (texto centrado). Opcionalmente esperar a que el jugador presione una tecla (‘I’) o gesto específico para volver al menú.</li>
                      <li>Si vida llega a cero, mostrar “Game Over” y regresar al menú o reiniciar nivel.</li>
                    </ul>
                  </li>
                  <li>Configuraciones de dificultad: en nivel 2 se incrementa velocidad de scroll, frecuencia de enemigos, mayor altitud de salto requerida o más plataformas móviles.</li>
                </ul>
              </li>
              <li><strong>Nivel Shooter de Naves (Level 3):</strong>
                <ul>
                  <li>Fondo espacial dibujado con <code>pantalla.draw_parallax_background</code> usando imágenes de <code>assets/backgrounds/espacio.jpg</code> o similares.</li>
                  <li>Clase <code>Spaceship</code> en <code>spaceship.py</code> maneja la nave del jugador: posición inicial, animaciones o rotación si aplica, vida y disparos.</li>
                  <li>Mapeo de gestos para shooter:
                    <ul>
                      <li>“piedra”: movimiento vertical (por ejemplo, subir o avance lateral leve según diseño).</li>
                      <li>“papel”: disparo principal (crear proyectil en posición de la nave, con efecto visual y sonido “shoot.wav”).</li>
                      <li>“tijeras”: activar escudo o cambiar arma (por ejemplo, modo ráfaga, misil especial), con animación y sonido asociado.</li>
                    </ul>
                  </li>
                  <li>Generación de enemigos y obstáculos:
                    <ul>
                      <li>Patrones definidos en <code>levels.py</code> o en configuraciones JSON: oleadas de enemigos con posiciones y comportamientos.</li>
                      <li>Scroll automático: el nivel avanza sin intervención; el jugador debe reaccionar con gestos para disparar o esquivar.</li>
                    </ul>
                  </li>
                  <li>Boss final:
                    <ul>
                      <li>Al finalizar oleadas, aparece sprite de boss (<code>assets/backgrounds/boss3.png</code> u otro), con patrones de ataque (disparos dirigidos, barreras). Mapea gestos para esquivar/defender y atacar: “papel” dispara contra boss, “tijeras” activa maniobra evasiva o cambio de arma, “piedra” puede servir para recargar o subir posición.</li>
                      <li>Gestión de vida del boss y del jugador: actualizar barras en UI (<code>draw_ui</code>), reproducir efectos (explosión final, sonido de victoria).</li>
                    </ul>
                  </li>
                  <li>Colisiones:
                    <ul>
                      <li>Entre disparos del jugador y enemigos/boss: detonaciones con animación y sonido.</li>
                      <li>Entre la nave y disparos enemigos: restar vida o terminar si vida=0.</li>
                    </ul>
                  </li>
                  <li>Al derrotar al boss: mostrar “Jefe derrotado” con texto centrado; reproducir música de victoria; esperar entrada de usuario (tecla o gesto) para volver al menú principal.</li>
                </ul>
              </li>
              <li><strong>Detección de teclado / gestos adicionales:</strong>
                <ul>
                  <li>Permite pulsar ‘q’ para salir de cualquier modo y regresar al menú.</li>
                  <li>Opcionalmente, un gesto especial o combinación (por ejemplo, mantener “papel” + “tijeras”) podría pausar o reiniciar.</li>
                </ul>
              </li>
              <li><strong>Retroalimentación visual y audio:</strong>
                <ul>
                  <li>En cada acción clave, se dibuja texto en pantalla con <code>cv2.putText</code> o Pygame <code>font.render</code>: “Salto”, “Disparo”, “Escudo activado”, “Vida: X”.</li>
                  <li>Se reproducen sonidos vía <code>pygame.mixer</code> (sonidos de salto, disparo, explosión, música de fondo, alerta de vida baja).</li>
                  <li>Opcional síntesis de voz (gTTS) para narrar eventos clave (“Nivel completado”, “Jefe derrotado”), aunque en este proyecto puede usarse texto y sonidos pregrabados.</li>
                </ul>
              </li>
              <li><strong>Calibración y optimización:</strong>
                <ul>
                  <li>Ajustar parámetros de <code>HandDetector</code>: <code>detectionCon</code>, <code>maxHands</code>, tolerancias de <code>fingersUp</code> para robustez en distintas condiciones de iluminación.</li>
                  <li>Reducir resolución de captura si FPS baja: e.g., capturar a 640×480 en vez de 1280×720.</li>
                  <li>Cache de assets en <code>pantalla.py</code> para evitar recargas: imágenes y sonidos se cargan una vez.</li>
                </ul>
              </li>
              <li><strong>Recursos y gestión de archivos:</strong>
                <ul>
                  <li>Carpeta <code>assets/backgrounds/</code>: fondos de plataformas y espacio.</li>
                  <li>Carpeta <code>assets/sprites/</code> o similar: imágenes de jugador, enemigos, naves, obstáculos.</li>
                  <li>Carpeta <code>assets/gestos/</code>: <code>Rock.png</code>, <code>Paper.png</code>, <code>Scissors.png</code> para mostrar feedback de detección de gesto.</li>
                  <li>Carpeta <code>assets/sounds/</code>: <code>jump.wav</code>, <code>shoot.wav</code>, <code>explosion.wav</code>, <code>boss.wav</code>, etc.</li>
                  <li>Archivos de configuración (JSON/CSV) para patrones de enemigos o parámetros de niveles.</li>
                </ul>
              </li>
              <li><strong>Dependencias:</strong>
                <ul>
                  <li>Python 3.x</li>
                  <li>OpenCV (<code>opencv-python</code>) y CVZone (<code>cvzone</code>, <code>mediapipe</code>) para detección de gestos.</li>
                  <li>Pygame para renderizado 2D, gestión de sonido y detección de teclado.</li>
                  <li>Tkinter (opcional) para menú inicial, o todo en Pygame si prefieres una sola ventana.</li>
                  <li>gTTS o librería de audio para síntesis de voz (opcional).</li>
                  <li>Pillow (<code>PIL</code>) si necesitas manipular sprites o fondos antes de mostrarlos.</li>
                  <li>Otras librerías estándar: <code>numpy</code>, <code>random</code>, <code>time</code>, <code>json</code>.</li>
                </ul>
              </li>
              <li><strong>Pruebas y grabación de demo:</strong>
                <ul>
                  <li>Ejecutar localmente en distintas condiciones de iluminación y ángulos de cámara para garantizar detección fiable de gestos durante el juego.</li>
                  <li>Grabar con OBS Studio o Game Bar: mostrar menú inicial, Nivel 1, Nivel 2, luego Nivel 3 con boss final, evidenciando cómo los gestos RPS controlan las acciones.</li>
                  <li>Tomar capturas de pantalla representativas de cada nivel para la imagen en el portfolio.</li>
                  <li>Opcionalmente editar vídeo de demo (cortar inicio/fin, añadir texto de presentación) antes de subir a YouTube.</li>
                </ul>
              </li>
            </ul>
            <p>
              <!-- Enlace al repositorio de código: reemplaza con tu URL real -->
              <a href="https://github.com/gameandnight/juego-plataformas-naves-gestos" class="btn btn-primary btn-sm" target="_blank" rel="noopener">Código</a>
              <!-- Si tuvieras demo online, descomenta y ajusta este enlace -->
              <!-- <a href="https://tu-demo-juego-gestos.streamlitapp.com" class="btn btn-secondary btn-sm" target="_blank" rel="noopener">Demo</a> -->
              <!-- Enlace a vídeo de demostración en YouTube mostrando los tres niveles y boss final controlados con gestos -->
              <a href="https://www.youtube.com/watch?v=ID_VIDEO_JUEGO_PLATAFORMAS" class="btn btn-info btn-sm" target="_blank" rel="noopener">Ver Vídeo</a>
            </p>
            <!-- Embed de vídeo (opcional): descomentar si deseas embeber el vídeo directamente -->
            <!--
            <div class="mt-3">
              <div class="ratio ratio-16x9">
                <iframe src="https://www.youtube.com/embed/ID_VIDEO_JUEGO_PLATAFORMAS" title="Demo Juego Plataformas y Naves con gestos" allowfullscreen></iframe>
              </div>
            </div>
            -->
          </div>
        </div>
      </div>
    </section>

    <footer class="bg-dark text-white text-center py-3">
      <div class="container"><small>&copy; 2025 Iker Redondo Serra</small></div>
    </footer>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
  </body>
</html>
